{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder with K-Means for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "# to import MNIST as torch tensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# load the training and test datasets\n",
    "train_data = datasets.MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data', train=False,\n",
    "                                  download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training and testing dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 100\n",
    "lr = 1e-3\n",
    "# how many epochs for training\n",
    "num_epochs = 25\n",
    "# latent space size\n",
    "z_dim = 10\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoencoder neural network design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cae(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cae, self).__init__()\n",
    "        # convolutional encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=3, padding=1),  # 16, 10, 10\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2),  # 16, 5, 5\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),  # 32, 3, 3\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1)  # 32, 2, 2\n",
    "        )\n",
    "        # autoencoder bottle neck\n",
    "        self.latent = nn.Sequential(\n",
    "            nn.Linear(32*2*2, z_dim),\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "        self.upscale = nn.Sequential(\n",
    "            nn.Linear(z_dim, 32*2*2),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # convolutional decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2),  # 16, 5, 5\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # 8, 15, 15\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),  # 1, 28, 28\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    # forward learning path\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.latent(x.view(-1, 32*2*2))\n",
    "        \n",
    "        bottle_neck = x\n",
    "        \n",
    "        x = self.upscale(x)\n",
    "        x = self.decoder(x.view(-1, 32, 2, 2))\n",
    "        return x, bottle_neck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAE model instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a CAE model\n",
    "model = cae()\n",
    "# set loss function\n",
    "criterion = nn.MSELoss()\n",
    "# choose an optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,\n",
    "                             weight_decay=1e-7)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load wieghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('cae+k-means on MNIST 19.01'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tensorboard input sample\n",
    "for x, y in iter(train_loader):\n",
    "    images = x\n",
    "grid = torchvision.utils.make_grid(images[-64:])\n",
    "tb = SummaryWriter()\n",
    "tb.add_image('images', grid)\n",
    "\n",
    "x, y = (0, 0)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_total_loss = 0\n",
    "    valid_total_loss = 0\n",
    "    start_time = time.time()\n",
    "    for batch_index, data in enumerate(train_loader):\n",
    "        img, _ = data\n",
    "        # training\n",
    "        if (batch_index+1)%10 != 0:\n",
    "            x += 1\n",
    "            # forward path\n",
    "            output, embed = model(img)\n",
    "            loss = criterion(output, img)\n",
    "            # back propagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_total_loss += loss.item()\n",
    "            tb.add_scalar('training loss/step', loss.item(), x)\n",
    "        # validating every tenth batch\n",
    "        else:\n",
    "            y += 1\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                output, _ = model(img)\n",
    "                model.train()\n",
    "                valid_total_loss += F.mse_loss(output, img).item()\n",
    "            tb.add_scalar('validation loss/step', F.mse_loss(output, img).item(), y)\n",
    "    \n",
    "    # tensorboard stuff\n",
    "    grid = torchvision.utils.make_grid(output[-64:])\n",
    "    tb.add_image('images', grid)\n",
    "    tb.add_histogram('test histo', embed, epoch)    \n",
    "    tb.add_scalar('training loss', train_total_loss/(54000/batch_size), epoch)\n",
    "    tb.add_scalar('validation loss', valid_total_loss/(6000/batch_size), epoch)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # log\n",
    "    print('epoch [{}/{}], training loss:{:.4f}, validation loss:{:.4f}, expected runtime:{:.4f} min'\n",
    "          .format(epoch+1, num_epochs, train_total_loss/(54000/batch_size), valid_total_loss/(6000/batch_size),\n",
    "                  (end_time - start_time)*num_epochs/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualizing reconstructed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "model.eval()\n",
    "\n",
    "# get sample outputs\n",
    "with torch.no_grad():\n",
    "    output, _ = model(images)\n",
    "    \n",
    "# print images and output in tensorborad\n",
    "grid = torchvision.utils.make_grid(images[:64])\n",
    "tb.add_image('real', grid)\n",
    "grid = torchvision.utils.make_grid(output[:64])\n",
    "tb.add_image('reconstructed', grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reconstruct the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the dataset through the trained model\n",
    "model.eval()\n",
    "for image_index, data in enumerate(train_loader):\n",
    "    images, itr_labels = data\n",
    "    # forward pass: compute embedded outputs by passing inputs to the model\n",
    "    decoded, encoded = model(images)\n",
    "    if not image_index:\n",
    "        #First group encoded in new array\n",
    "        embedded = encoded.detach().numpy()\n",
    "        #first group decoded\n",
    "        disembedded = decoded.detach().numpy()\n",
    "        #labels\n",
    "        labels = itr_labels.detach().numpy()\n",
    "        continue\n",
    "    #stacking the remaining data\n",
    "    embedded = np.vstack((embedded, encoded.detach().numpy()))\n",
    "    disembedded = np.vstack((disembedded, decoded.detach().numpy()))\n",
    "    labels = np.hstack((labels, itr_labels.detach().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clustering model instantiation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# create a k-means model to cluster the embedded features\n",
    "clustering_model = KMeans(n_clusters=10, tol = 1e-4, max_iter = 400).fit(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualizing results and performance evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the dataset through the trained model\n",
    "model.eval()\n",
    "for image_index, data in enumerate(test_loader):\n",
    "    images, itr_labels = data\n",
    "    # forward pass: compute embedded outputs by passing inputs to the model\n",
    "    decoded, encoded = model(images)\n",
    "    if not image_index:\n",
    "        #First group encoded in new array\n",
    "        embedded_test = encoded.detach().numpy()\n",
    "        #first group decoded\n",
    "        disembedded_test = decoded.detach().numpy()\n",
    "        #labels\n",
    "        labels_test = itr_labels.detach().numpy()\n",
    "        continue\n",
    "    #stacking the remaining data\n",
    "    embedded_test = np.vstack((embedded_test, encoded.detach().numpy()))\n",
    "    disembedded_test = np.vstack((disembedded_test, decoded.detach().numpy()))\n",
    "    labels_test = np.hstack((labels_test, itr_labels.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred = clustering_model.predict(embedded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import DataVisuals as dv\n",
    "\n",
    "\n",
    "view_results = dv.DataVisuals(disembedded.reshape(-1, 28,28), labels, clustering_model.labels_)\n",
    "view_results_test = dv.DataVisuals(disembedded_test.reshape(-1, 28,28), labels_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix of training set\n",
    "view_results.cm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix of testing set\n",
    "view_results_test.cm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scatter plot of subset of training set\n",
    "view_results.scat(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of subset of testing set\n",
    "view_results_test.scat(embedded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train metrics\n",
    "metric = dv.Metrics(labels, clustering_model.labels_)\n",
    "nmi = metric.nmi()\n",
    "ari = metric.ari()\n",
    "acc = metric.acc()\n",
    "print('NMI = {:.4f} \\nARI = {:.4f} \\nACC = {:.4f}'.format(nmi, ari, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test metrics\n",
    "metric = dv.Metrics(labels_test, labels_pred)\n",
    "nmi = metric.nmi()\n",
    "ari = metric.ari()\n",
    "acc = metric.acc()\n",
    "print('NMI = {:.4f} \\nARI = {:.4f} \\nACC = {:.4f}'.format(nmi, ari, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store wieghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'cae+k-means on MNIST 19.01')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
