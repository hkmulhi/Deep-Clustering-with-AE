{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Autoencoder with K-means on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# to import CIFAR-10 as torch tensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# load the training and test datasets\n",
    "train_data = datasets.CIFAR10(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root='data', train=False,\n",
    "                                  download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training and testing dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test dataloaders\n",
    "\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 100\n",
    "# how many epochs for training\n",
    "num_epochs = 25\n",
    "# latent space size\n",
    "z_dim = 50\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(32*32*3, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.BatchNorm1d(500),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(500, z_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32*32*3)\n",
    "        out = self.encode(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Linear(z_dim, 500),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(500, 1000),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1000, 32*32*3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.decode(input)\n",
    "        return output.view(-1, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.dis = nn.Sequential(\n",
    "            nn.Linear(z_dim, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.BatchNorm1d(500),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(500, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dis(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAE model instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "\n",
    "optim_dc = torch.optim.Adam(discriminator.parameters(), lr=1e-3)\n",
    "optim_de = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n",
    "optim_en = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "\n",
    "# set loss function\n",
    "criterion = nn.MSELoss()\n",
    "dc_criterion = nn.BCEWithLogitsLoss()\n",
    "gn_criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load wieghts"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "encoder.load_state_dict(torch.load('GAN feature extraction CIFAR10 - encoder 19.01'))\n",
    "decoder.load_state_dict(torch.load('GAN feature extraction CIFAR10 - decoder 19.01'))\n",
    "discriminator.load_state_dict(torch.load('GAN feature extraction CIFAR10 - discriminator 19.01'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training\n",
    "for x, y in iter(train_loader):\n",
    "    images = x\n",
    "grid = torchvision.utils.make_grid(images[-64:])\n",
    "tb = SummaryWriter()\n",
    "tb.add_image('images', grid)\n",
    "\n",
    "x = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    total_loss = 0\n",
    "    dc_total_loss = 0\n",
    "    gn_total_loss = 0\n",
    "\n",
    "    for data in (train_loader):\n",
    "        x += 1\n",
    "        img, _ = data\n",
    "        # Autoencoder training\n",
    "        embed = encoder(img)\n",
    "        output = decoder(embed)\n",
    "        loss = criterion(output, img)\n",
    "        # back propagation\n",
    "        optim_en.zero_grad()\n",
    "        optim_de.zero_grad()\n",
    "        loss.backward()\n",
    "        optim_en.step()\n",
    "        optim_de.step()\n",
    "        total_loss += loss.item()\n",
    "        tb.add_scalar('Loss ae/step', loss.item(), x)\n",
    "        \n",
    "        \n",
    "        # discriminator training\n",
    "        for i in range(4):\n",
    "            # Generating data\n",
    "            real_distribution = torch.randn(batch_size, z_dim)\n",
    "            encoder_output = encoder(img).detach()\n",
    "            # GAN training\n",
    "            d_real = discriminator(real_distribution)\n",
    "            d_fake = discriminator(encoder_output)\n",
    "            optim_dc.zero_grad()\n",
    "            dc_loss_real = dc_criterion(d_real, Variable(torch.ones(batch_size, 1)))\n",
    "            dc_loss_real.backward()\n",
    "            dc_loss_fake = dc_criterion(d_fake, Variable(torch.zeros(batch_size, 1)))\n",
    "            dc_loss_fake.backward()\n",
    "            \n",
    "            optim_dc.step()\n",
    "        dc_total_loss += 0.5 * (dc_loss_real.item() + dc_loss_fake.item())\n",
    "        tb.add_scalar('Loss dc/step', 0.5*(dc_loss_real.item() + dc_loss_fake.item()), x)\n",
    "        # generator training\n",
    "        optim_en.zero_grad()\n",
    "        encoder_output = encoder(img)\n",
    "        d_fake = discriminator(encoder_output)\n",
    "        gn_loss = gn_criterion(d_fake, Variable(torch.ones(batch_size, 1)))\n",
    "        \n",
    "        gn_loss.backward()\n",
    "        optim_en.step()\n",
    "        gn_total_loss += gn_loss.item()\n",
    "        tb.add_scalar('Loss gn/step', gn_loss.item(), x)\n",
    "    \n",
    "    # tensorboard stuff\n",
    "    grid = torchvision.utils.make_grid(output[-64:])\n",
    "    tb.add_image('images', grid)\n",
    "    tb.add_histogram('test histo', embed, epoch)    \n",
    "    tb.add_scalar('Loss ae', total_loss/(50000/batch_size), epoch)\n",
    "    tb.add_scalar('Loss dc', dc_total_loss/(50000/batch_size), epoch)\n",
    "    tb.add_scalar('Loss gn', gn_total_loss/(50000/batch_size), epoch)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    # log\n",
    "    print('epoch [{}/{}], loss dc:{:.4f}, loss gn:{:.4f}, loss ae:{:.4f}, expected runtime:{:.4f} min'\n",
    "          .format(epoch+1, num_epochs, \n",
    "                  dc_total_loss/(50000/batch_size), gn_total_loss/(50000/batch_size), \n",
    "                  total_loss/(50000/batch_size), (end_time - start_time)*num_epochs/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualizing reconstructed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# get sample outputs\n",
    "with torch.no_grad():\n",
    "    output = decoder(encoder(images))\n",
    "    \n",
    "# print images and output in tensorborad\n",
    "grid = torchvision.utils.make_grid(images[:64])\n",
    "tb.add_image('real', grid)\n",
    "grid = torchvision.utils.make_grid(output[:64])\n",
    "tb.add_image('reconstructed', grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reconstruct the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the dataset through the trained model\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "for image_index, data in enumerate(train_loader):\n",
    "    images, itr_labels = data\n",
    "    # forward pass: compute embedded outputs by passing inputs to the model\n",
    "    encoded = encoder(images)\n",
    "    decoded = decoder(encoded)\n",
    "    if not image_index:\n",
    "        #First group encoded in new array\n",
    "        embedded = encoded.detach().numpy()\n",
    "        #first group decoded\n",
    "        disembedded = decoded.detach().numpy()\n",
    "        #labels\n",
    "        labels = itr_labels.detach().numpy()\n",
    "        continue\n",
    "    #stacking the remaining data\n",
    "    embedded = np.vstack((embedded, encoded.detach().numpy()))\n",
    "    disembedded = np.vstack((disembedded, decoded.detach().numpy()))\n",
    "    labels = np.hstack((labels, itr_labels.detach().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clustering model instantiation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# create a k-means model to cluster the embedded features\n",
    "clustering_model = KMeans(n_clusters=10, tol = 1e-4, max_iter = 400).fit(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualizing results and performance evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the dataset through the trained model\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "for image_index, data in enumerate(test_loader):\n",
    "    images, itr_labels = data\n",
    "    # forward pass: compute embedded outputs by passing inputs to the model\n",
    "    encoded = encoder(images)\n",
    "    decoded = decoder(encoded)    \n",
    "    if not image_index:\n",
    "        #First group encoded in new array\n",
    "        embedded_test = encoded.detach().numpy()\n",
    "        #first group decoded\n",
    "        disembedded_test = decoded.detach().numpy()\n",
    "        #labels\n",
    "        labels_test = itr_labels.detach().numpy()\n",
    "        continue\n",
    "    #stacking the remaining data\n",
    "    embedded_test = np.vstack((embedded_test, encoded.detach().numpy()))\n",
    "    disembedded_test = np.vstack((disembedded_test, decoded.detach().numpy()))\n",
    "    labels_test = np.hstack((labels_test, itr_labels.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred = clustering_model.predict(embedded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import DataVisuals as dv\n",
    "\n",
    "\n",
    "view_results = dv.DataVisuals(disembedded.reshape(-1, 3, 32,32), labels, clustering_model.labels_)\n",
    "view_results_test = dv.DataVisuals(disembedded_test.reshape(-1, 3, 32, 32), labels_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix of training set\n",
    "view_results.cm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix of testing set\n",
    "view_results_test.cm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scatter plot of subset of training set\n",
    "view_results.scat(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of subset of testing set\n",
    "view_results_test.scat(embedded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train metrics\n",
    "metric = dv.Metrics(labels, clustering_model.labels_)\n",
    "nmi = metric.nmi()\n",
    "ari = metric.ari()\n",
    "acc = metric.acc()\n",
    "print('NMI = {:.4f} \\nARI = {:.4f} \\nACC = {:.4f}'.format(nmi, ari, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test metrics\n",
    "metric = dv.Metrics(labels_test, labels_pred)\n",
    "nmi = metric.nmi()\n",
    "ari = metric.ari()\n",
    "acc = metric.acc()\n",
    "print('NMI = {:.4f} \\nARI = {:.4f} \\nACC = {:.4f}'.format(nmi, ari, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store wieghts"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.save(encoder.state_dict(), 'GAN feature extraction CIFAR10 - encoder 20.01')\n",
    "torch.save(decoder.state_dict(), 'GAN feature extraction CIFAR10 - decoder 20.01')\n",
    "torch.save(discriminator.state_dict(), 'GAN feature extraction CIFAR10 - discriminator 20.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
