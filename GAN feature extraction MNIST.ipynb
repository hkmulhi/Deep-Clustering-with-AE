{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the encoder using GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "\n",
    "# to import MNIST as torch tensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# load the training and test datasets\n",
    "train_data = datasets.MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data', train=False,\n",
    "                                  download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test dataloaders\n",
    "\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 100\n",
    "# how many epochs for training\n",
    "num_epochs = 40\n",
    "# latent space size\n",
    "z_dim = 10\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calc_gradient_penalty borrowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import scipy.misc\n",
    "import torch.autograd as autograd\n",
    "\n",
    "\n",
    "\n",
    "def calc_gradient_penalty(model, real_data, gen_data):\n",
    "    datashape = model.shape\n",
    "    alpha = torch.rand(batch_size, 1)\n",
    "    real_data = real_data.view(batch_size, -1)\n",
    "    if True:\n",
    "        alpha = alpha.expand(real_data.size())\n",
    "    else:\n",
    "        alpha = alpha.expand(batch_size, real_data.nelement()//batch_size)\n",
    "        alpha = alpha.contiguous().view(batch_size, -1)\n",
    "    interpolates = alpha * real_data + ((1 - alpha) * gen_data)\n",
    "    interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
    "    disc_interpolates = model(interpolates)\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, \n",
    "            inputs=interpolates,\n",
    "            grad_outputs=torch.ones(disc_interpolates.size()),      \n",
    "            create_graph=True, \n",
    "            retain_graph=True, \n",
    "            only_inputs=True)[0]\n",
    "\n",
    "    #if args.dataset != 'mnist':\n",
    "    #    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10\n",
    "    return gradient_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.shape = (1, 28, 28)\n",
    "        self.dim = z_dim\n",
    "        convblock = nn.Sequential(\n",
    "                nn.Conv2d(1, self.dim, 5, stride=2, padding=2),\n",
    "                nn.Dropout(p=0.3),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(self.dim, 2*self.dim, 5, stride=2, padding=2),\n",
    "                nn.Dropout(p=0.3),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(2*self.dim, 4*self.dim, 5, stride=2, padding=2),\n",
    "                nn.Dropout(p=0.3),\n",
    "                nn.ReLU(True),\n",
    "                )\n",
    "        self.main = convblock\n",
    "        self.output = nn.Linear(4*4*4*self.dim, self.dim)\n",
    "\n",
<<<<<<< Updated upstream
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(100, z_dim),\n",
    "            nn.Sigmoid() # not sure\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(-1, 28*28)\n",
    "        z = self.model(img_flat)\n",
    "        return z"
=======
    "    def forward(self, input):\n",
    "        input = input.view(-1, 1, 28, 28)\n",
    "        out = self.main(input)\n",
    "        out = out.view(-1, 4*4*4*self.dim)\n",
    "        out = self.output(out)\n",
    "        return out.view(-1, self.dim)"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a decoder/generation\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dim = z_dim\n",
    "        self.in_shape = int(np.sqrt(self.dim))\n",
    "        self.shape = (self.in_shape, self.in_shape, 1)\n",
    "        preprocess = nn.Sequential(\n",
    "                nn.Linear(self.dim, 4*4*4*self.dim),\n",
    "                nn.ReLU(True),\n",
    "                )\n",
    "        block1 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(4*self.dim, 2*self.dim, 5),\n",
    "                nn.ReLU(True),\n",
    "                )\n",
    "        block2 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(2*self.dim, self.dim, 5),\n",
    "                nn.ReLU(True),\n",
    "                )\n",
    "        deconv_out = nn.ConvTranspose2d(self.dim, 1, 8, stride=2)\n",
    "        self.block1 = block1\n",
    "        self.block2 = block2\n",
    "        self.deconv_out = deconv_out\n",
    "        self.preprocess = preprocess\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.preprocess(input)\n",
    "        output = output.view(-1, 4*self.dim, 4, 4)\n",
    "        output = self.block1(output)\n",
    "        output = output[:, :, :7, :7]\n",
    "        output = self.block2(output)\n",
    "        output = self.deconv_out(output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output.view(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.shape = (1, 28, 28)\n",
    "        self.dim = z_dim\n",
    "        convblock = nn.Sequential(\n",
    "                nn.Conv2d(1, self.dim, 5, stride=2, padding=2),\n",
    "                nn.Dropout(p=0.3),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(self.dim, 2*self.dim, 5, stride=2, padding=2),\n",
    "                nn.Dropout(p=0.3),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(2*self.dim, 4*self.dim, 5, stride=2, padding=2),\n",
    "                nn.Dropout(p=0.3),\n",
    "                nn.ReLU(True),\n",
    "                )\n",
    "        self.main = convblock\n",
    "        self.output = nn.Linear(4*4*4*self.dim, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(-1, 1, 28, 28)\n",
    "        out = self.main(input)\n",
    "        out = out.view(-1, 4*4*4*self.dim)\n",
    "        out = self.output(out)\n",
    "        return out.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "\n",
    "optimizerD = optim.Adam(discriminator.parameters(), lr=2e-4, betas=(0.5, 0.9))\n",
    "optimizerG = optim.Adam(decoder.parameters(), lr=2e-4, betas=(0.5, 0.9))\n",
    "optimizerE = optim.Adam(encoder.parameters(), lr=2e-4, betas=(0.5, 0.9))\n",
    "\n",
    "schedulerD = optim.lr_scheduler.ExponentialLR(optimizerD, gamma=0.99)\n",
    "schedulerG = optim.lr_scheduler.ExponentialLR(optimizerG, gamma=0.99) \n",
    "schedulerE = optim.lr_scheduler.ExponentialLR(optimizerE, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/40], autoencoder loss:0.1084, discriminator loss:-7.3662, generator loss:3.1004\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c088929ad2aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mfake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mae_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mae_criterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_data_v\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mae_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0moptimizerE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0moptimizerG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \"\"\"\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ae_criterion = nn.MSELoss()\n",
    "iteration = 0\n",
    "one = torch.tensor(1, dtype=torch.float)\n",
    "mone = (one * -1)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, targets) in enumerate(train_loader):\n",
    "        start_time = time.time()\n",
    "        \"\"\" Update AutoEncoder \"\"\"\n",
    "        for p in discriminator.parameters():\n",
    "            p.requires_grad = False\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        real_data_v = autograd.Variable(data)\n",
    "        real_data_v = real_data_v.view(batch_size, -1)\n",
    "        encoding = encoder(real_data_v)\n",
    "        fake = decoder(encoding)\n",
    "        ae_loss = ae_criterion(fake, real_data_v)\n",
    "        ae_loss.backward(one)\n",
    "        optimizerE.step()\n",
    "        optimizerG.step()\n",
    "\n",
    "        \"\"\" Update D network \"\"\"\n",
    "        for p in discriminator.parameters():  \n",
    "            p.requires_grad = True \n",
    "        for i in range(5):\n",
    "            real_data_v = autograd.Variable(data)\n",
    "            # train with real data\n",
    "            discriminator.zero_grad()\n",
    "            D_real = discriminator(real_data_v)\n",
    "            D_real = D_real.mean()\n",
    "            D_real.backward(mone)\n",
    "            # train with fake data\n",
    "            noisev = torch.randn(batch_size, z_dim)\n",
    "            fake = autograd.Variable(decoder(noisev).data)\n",
    "            inputv = fake\n",
    "            D_fake = discriminator(inputv)\n",
    "            D_fake = D_fake.mean()\n",
    "            D_fake.backward(one)\n",
    "            # train with gradient penalty \n",
    "            gradient_penalty = calc_gradient_penalty(discriminator, real_data_v.data, fake.data)\n",
    "            gradient_penalty.backward()\n",
    "\n",
    "            D_cost = D_fake - D_real + gradient_penalty\n",
    "            Wasserstein_D = D_real - D_fake\n",
    "            \n",
    "            optimizerD.step()\n",
    "\n",
    "        # Update generator network (GAN)\n",
    "        noisev = torch.randn(batch_size, z_dim)\n",
    "        fake = decoder(noisev)\n",
    "        G = discriminator(fake)\n",
    "        G = G.mean()\n",
    "        G.backward(mone)\n",
    "        G_cost = -G\n",
    "        optimizerG.step() \n",
    "        \n",
    "        schedulerG.step()\n",
    "        schedulerD.step()\n",
    "        schedulerE.step()\n",
    "\n",
    "    # log\n",
    "    print('epoch [{}/{}], autoencoder loss:{:.4f}, discriminator loss:{:.4f}, generator loss:{:.4f}'\n",
    "      .format(epoch+1, num_epochs, ae_loss.item(), D_cost.item(), G_cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build a GAN model\n",
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# set loss function\n",
    "auto_criterion = torch.nn.MSELoss()\n",
    "\n",
    "# choose an optimizer\n",
    "e_optimizer = torch.optim.Adam(encoder.parameters(), lr=lr)\n",
    "d_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "g_optimizer = torch.optim.Adam(encoder.parameters(), lr=gan_lr)\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=gan_lr)\n",
    "\n",
    "print(encoder, decoder, discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        img, _ = data\n",
    "        \n",
    "        ## zero out previous grads\n",
    "        #-------------------------\n",
    "        e_optimizer.zero_grad()\n",
    "        d_optimizer.zero_grad()\n",
    "        \n",
    "        ## Training the autoencoder\n",
    "        #--------------------------\n",
    "        # forward path\n",
    "        z_encoder = encoder(img)\n",
    "        output = decoder(z_encoder)\n",
    "        loss_auto = auto_criterion(output + 1e-15, img + 1e-15)\n",
    "        # back propagation\n",
    "        loss_auto.backward()\n",
    "        e_optimizer.step()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        ## generating data for discriminator\n",
    "        #-----------------------------------\n",
    "        #encoder.eval()\n",
    "        z_real = torch.randn(batch_size, z_dim) *5.\n",
    "        z_fake = encoder(img)\n",
    "        \n",
    "#______________\n",
    "\n",
    "\n",
    "        # log\n",
    "    print('epoch [{}/{}], autoencoder loss:{:.4f}, discriminator loss:, generator loss:'\n",
    "          .format(epoch+1, num_epochs, loss_auto.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualizing reconstructed results\n",
    "### NOTE TO SELF: to be automated through DV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABXEAAADrCAYAAAAv1NW3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3daZRcVbkw4FPdmROEJCQQZE4EQWYCIgKCoswIGjCK6BUFFVAUZVBQEUSXoDggg7iuU1QEmUSGXASFECFyEyCYMK3ES0IgQIAkkIlM9f34lpu9D6miu7qr6lT38/x699qnq940b+86Z3POW6VyuZwBAAAAAFBMbc1OAAAAAACAymziAgAAAAAUmE1cAAAAAIACs4kLAAAAAFBgNnEBAAAAAArMJi4AAAAAQIH16czBpVKpXK9E6LQXy+XyiGYn0RHqpjjK5XKp2Tl0hJopFGsNtVA31ELdUAt1Qy3UDbVQN3Saa3BqUHGtcSdu65rT7ASAXsFaQy3UDbVQN9RC3VALdUMt1A3QCBXXGpu4AAAAAAAFZhMXAAAAAKDAbOICAAAAABSYTVwAAAAAgAKziQsAAAAAUGA2cQEAAAAACswmLgAAAABAgdnEBQAAAAAoMJu4AAAAAAAF1qfZCUAjffWrX03GAwcODPFOO+2UzI0bN67i61xxxRXJ+P777w/xhAkTupIiAAAAACTciQsAAAAAUGA2cQEAAAAACkw7BXq8a665JsTVWiTkrV27tuLcZz/72WR84IEHhviee+5J5ubOndvh96T32GabbUL8+OOPJ3OnnXZaiC+99NKG5URjDB48OBlffPHFIc6vLdOmTUvGxxxzTIjnzJlTh+wAAKC1DB06NBlvvvnmHfq5/Pn0l7/85RDPmDEjmXvyySdDPH369M6mCN3CnbgAAAAAAAVmExcAAAAAoMBs4gIAAAAAFJieuPQ4cQ/cLOt4H9x8X9L/+Z//CfHWW2+dzB1xxBHJePTo0SE+7rjjkrnvfe97HXp/epddd901xPn+y/PmzWt0OjTQqFGjkvGJJ54Y4nwt7L777sn48MMPD/Fll11Wh+xopt122y0Z33DDDSHecsst6/7+H/jAB5LxY489FuKnn3667u9PscTnOjfffHMyd+qpp4b4yiuvTObWrFlT38So2ciRI0N87bXXJnP33XdfiK+66qpk7qmnnqprXnnrr79+Mt5vv/1CPHHixGRu1apVDckJaL7DDjssGR955JEh3n///ZO5MWPGdOg14z63WZZlW2yxRYj79+9f8efa29s79PrQ3dyJCwAAAABQYDZxAQAAAAAKTDsFeoSxY8eG+Oijj6543MyZM5Nx/AjGiy++mMwtWbIkxP369UvmpkyZkox33nnnEA8fPrwDGdPb7bLLLiFeunRpMnfjjTc2Oh3qbMSIESH+zW9+08RMKLKDDjooGVd7jK8e8q2CTjjhhBCPHz++obnQePnzl8svv7zisT/72c9C/Mtf/jKZW758efcmRs2GDh2ajOPz4HzLgueffz7EjW6fkGVpPtOmTUvm4s/QfJuhWbNm1TcxqnrLW94S4nwLuR122CHEBx54YDKnDQb/EbclzLIsO+WUU0IctxzLsiwbOHBgMi6VSl1+/2222abLrwGN5E5cAAAAAIACs4kLAAAAAFBgNnEBAAAAAAqs6T1xx40bl4zjvifPPvtsMrdixYoQ//73v0/mnnvuuRDrjdT7jBo1KsT53jhx/698v8H58+d36PW/8pWvJOPtt9++4rG33nprh16T3iXuC5ZlWXbqqaeGeMKECY1Ohzr74he/mIyPOuqoEO+55541v+5+++0X4ra29P/DTp8+PcSTJk2q+T1orD59Xj8VO/TQQ5uYyRv7UJ5++ukhHjx4cDKX7+VN64vXlyzLsk033bTisVdffXWI4/Nzmm/DDTcM8TXXXJPMDRs2LMT5nsdf+MIX6pvYmzj33HNDvNVWWyVzn/3sZ0PsOq+5jjvuuGR84YUXhnizzTar+HNx79wsy7KXXnqpexOjZeU/a0477bS6v+fjjz8e4vx35tB6xowZE+L4MzDL3vh9Sfvvv3+I165dm8xdeeWVIf7HP/6RzBXps8eduAAAAAAABWYTFwAAAACgwJreTuGiiy5KxltuuWWHfi5+rCbLsuzVV18NcTNuiZ83b16I8/+mqVOnNjqdXucvf/lLiOPb6bMsrY2XX365ptcfP358Mu7bt29Nr0Pv9fa3vz0Zx48m5x93pPX96Ec/Ssb5x3Vq9aEPfWidcZZl2Zw5c0L8kY98JJnLPyZPcRxwwAEhfte73pXM5c8n6m3o0KHJOG4dNGjQoGROO4XW179//2R8zjnndPhn4zZA5XK523Ki63bbbbcQx4+N5p1//vkNyKayd7zjHck4bl124403JnPOk5orftz9xz/+cTI3fPjwEFdbCy699NJkHLcVy7Lar9Eojvxj7HFbhPyj6RMnTgzxa6+9lswtXrw4xPlzjXxrpzvuuCPEM2bMSOb++c9/hvihhx5K5pYvX17xPSimuDVhfv2Ir4nyddgZ73znO0O8evXqZO6JJ54I8eTJk5O5uNZXrlxZ8/t3lDtxAQAAAAAKzCYuAAAAAECB2cQFAAAAACiwpvfEPfHEE5PxTjvtFOLHHnssmdtuu+1CHPd7yrK059Nee+2VzD399NMh3myzzTqcW74PxoIFC0I8atSoij83d+7cZKwnbmPFfSG74owzzgjxNttsU/XYuOdOHMN/nHnmmck4rlNrRM9w2223hbitrXv+H+lLL72UjJcsWRLiLbbYIpnbaqutQvzAAw8kc+3t7d2SD10X9/TKsiy7+uqrQzx79uxk7rvf/W5DcvqPD37wgw19P5prxx13TMa77757xWPz58S33357XXKi80aOHJmMP/zhD1c89tOf/nSI4+uaRon74N55550Vj8v3xI2/34LG++pXvxriYcOG1fQa+V79Bx98cDK+8MILQ5zvn9uIHpPUJu5RG/enzbIs23nnnUN89NFHV3yNKVOmJON4n+epp55K5jbffPNkHH8vUXd9/wTNE+8FnnLKKclcvIa85S1vqfgazzzzTDK+9957k/H//d//hTh/fR5/h8iee+6ZzMVr36GHHprMTZ8+PcRXXnllxdy6iztxAQAAAAAKzCYuAAAAAECBNb2dwl133VV1HJs4cWLFuaFDh4Z4l112Sebi26L32GOPDue2YsWKZPzkk0+GON/qIb69Ov84JK3h8MMPT8bnn39+iPv165fMvfDCC8n4a1/7WoiXLVtWh+xoNVtuuWUyHjt2bDKO15OlS5c2IiW62Xve855kvO2224Y4/0hXRx/xyj+Ck380bfHixSF+73vfm8ydc845FV/385//fIivuOKKDuVCfZx77rnJOH4UMf94adw+o17i85d8TXs0sWer9th9Xn4tojh++MMfJuOPf/zjIY6vgbIsy/70pz81JKdK9t133xBvtNFGydyvf/3rEP/ud79rVEqsQ75d06c+9amKxz7yyCMhfv7555O5Aw88sOLPrb/++sk4btnw+9//Ppl77rnnKidLQ+Wvif/whz+EOG6fkGVpS6hq7VPy8i0UYvm2lbS2n//858k4brux4YYbVvy5/J7hv/71rxB//etfT+bye3qxvffeOxnH10u//OUvk7l4jzG/1l122WUhvv7665O5erQucicuAAAAAECB2cQFAAAAACgwm7gAAAAAAAXW9J643WXhwoUh/vvf/17xuGo9d99M3Dss7sGbZWkfjmuuuabm96B58j1L8z1/Yvn/xvfcc09dcqJ15XtL5tWjPw71F/c6/uMf/5jMVevdFJszZ04yjnsnffvb307mqvXYzr/OSSedFOIRI0YkcxdddFGIBwwYkMz97Gc/C/GqVasqvh+1GzduXIgPPfTQZG7WrFkhnjp1asNy+o+4l3K+B+7dd98d4kWLFjUqJRpkv/32qzq/cuXKEFfruU1zlcvlZBz/HT/77LPJXPzftF4GDhwY4nxvwpNPPjnE+bxPOOGE+iZGh+W/X2a99dYL8b333pvMxee7+fOLj370oyHO18Lo0aOT8cYbbxziP//5z8ncIYccEuKXX365au50vyFDhoQ4/h6YLEu/U+bFF19M5n7wgx+E2HfG9F75deHMM88M8Wc+85lkrlQqhTh/rRx/p8fFF1+czNX6/TLDhw9Pxu3t7SE+77zzkrn4+7nyfcMbzZ24AAAAAAAFZhMXAAAAAKDAekw7hXoYOXJkMr788stD3NaW7n+ff/75IfaYR+u46aabQvyBD3yg4nG//e1vk/G5555bt5zoGXbccceq8/Hj7bSOPn1e/9jsaPuELEtbrowfPz6Zyz9+1lH5dgrf+973QnzJJZckc4MGDQpxvvZuvvnmEM+ePbumXKjumGOOCXH83yLL0nOLRohbgmRZlh133HEhXrNmTTL3ne98J8RabfQMe++99zrjdYkfT3z44YfrlhP1c9hhhyXjO+64I8T5Finxo6qdkW8ftf/++4d4r732qvhz1113XU3vR/31798/GcetL370ox9V/LkVK1Yk41/96lchjj8HsyzLtt5664qvk3/0vhFtQKjsqKOOCvHZZ5+dzM2dOzfE++67bzK3ePHi+iZGS4g/E7Isy84444wQx+0TsizLnnnmmRDHrUyzLMseeOCBmt4/bpGQZVm22WabhTi/x3PbbbeFON8+NZbPe8KECSFuRPsxd+ICAAAAABSYTVwAAAAAgAKziQsAAAAAUGB64lZxyimnJOMRI0aEeOHChcncE0880ZCc6JpRo0Yl47gfXL7/U9ynMu4LmGVZtmTJkjpkR6uLe7996lOfSuYeeuihZPzXv/61ITnRHFOnTk3GJ5xwQohr7YH7ZuLetnGf0yzLsj322KMu78m6rb/++sm4Wl/IWvtQ1uqkk05KxnFv58ceeyyZ+/vf/96QnGiczqwFja5NavOTn/wkGR9wwAEh3mSTTZK5/fbbL8T5nn5HHnlkTe+ff524f2rev//97xB//etfr+n9qL+PfvSjFefyfZbj7xepZuzYsR1+/ylTpiRj113NVa1/enx9M2/evEakQ4vJ96TNf/9CbPXq1SF+5zvfmcyNGzcuxG9/+9srvsby5cuT8XbbbVdxnL8m22ijjSq+buz5559Pxo3+Dgl34gIAAAAAFJhNXAAAAACAAtNOIefd7353iM8+++yKxx111FHJeMaMGXXLie5z/fXXJ+Phw4dXPPZ3v/tdiGfPnl23nOg5DjzwwBAPGzYsmZs4cWIyXrFiRUNyon7a2ir/f9D8I0CNED/Sms+tWq7nnXdeiI8//vhuz6s3yrfneetb3xriq6++utHpJEaPHl1xzrlMz1ftkeZFixYlY+0UWsO0adOS8U477RTiXXbZJZk7+OCDQ3zGGWckcwsWLAjxb37zmw6//4QJE5Lx9OnTKx573333hdi5dXHlP6fiVhv5lizxY8077rhjMnf00UeHeOjQoclcfr2J50888cRkLq6xRx99tGrudL/4Mfa8eE351re+lcz9+c9/DvHDDz/c/YnREv72t78l47hVV3ztnGVZtvnmm4f4pz/9aTJXrVVP3KIh376hmmrtE9auXZuMb7zxxhB/8YtfTObmz5/f4ffsDu7EBQAAAAAoMJu4AAAAAAAFZhMXAAAAAKDA9MTNOfTQQ0Pct2/fZO6uu+4K8f3339+wnOiauI/TbrvtVvG4u+++Oxnn+/rAm9l5551DnO/bc9111zU6Hergc5/7XIjzvZKa7YgjjgjxrrvumszFuebzjnvi0j1effXVZBz3gov7VWZZ2j/75Zdfrks+I0eODHG13naTJ0+uy/vTPPvss08y/tjHPlbx2MWLFyfjefPm1SUn6mvhwoUhjnsP5sdnnXVWt7zf1ltvnYzj/uz5Pphf/epXu+U9qa8777wzGcdrQ77vbdyjtlrPyvxrnnLKKcn4lltuCfHb3va2ZC7uPxmfh9EYI0aMCHH+HDL+DoBvfvObydy5554b4iuvvDKZmzJlSojjPqhZlmWzZs0K8cyZM6vm9o53vCPE+f0Zn2HFsHz58mQc98reYIMNkrn4O6ni76rKsix76aWXQjx37txkLq7D+Ho8y7Jszz337GTG/99VV12VjL/+9a+HON/Tu9HciQsAAAAAUGA2cQEAAAAACswmLgAAAABAgfX6nrgDBw5MxgcffHCIV65cmczFPVJXrVpV38So2fDhw5Nx3L8k3+c4lu/btWTJku5NjB5n4403Tsb77rtviJ944olk7sYbb2xITtRX3He2GeK+ZNtvv30yF6911SxYsCAZ+zzrfvn+X7Nnzw7xhz/84WTu1ltvDfEll1xS0/vtsMMOyTjfo3LLLbcMcbWehUXr80zX5c+J2toq37/x17/+td7p0APl+2DGa0y+727+84diyvdnP/bYY0Oc/46H9ddfv+LrXHrppSHO18KKFSuS8Q033BDiuC9mlmXZQQcdFOLRo0cnc/HnK/Xxgx/8IMSnn356h38u/rw5+eSTk7n8uDvk15f4+27Gjx/f7e9H1+V7y+b/9mvx29/+NhlX64mb/w6LuL5//etfJ3Nr1qzpcm7dxZ24AAAAAAAFZhMXAAAAAKDAen07hTPOOCMZ77rrriGeOHFiMnffffc1JCe65itf+Uoy3mOPPSoee9NNN4U4bpcBHfFf//VfyXjkyJEhvv322xucDb3BOeecE+JTTjmlwz/31FNPhfiTn/xkMjd37twu50V18edLqVRK5g477LAQX3311TW9/osvvpiM8y0TNtxwww69Tv7RMVrfuHHjKs7lH2P8+c9/Xu906AGOOeaYZPyJT3wiGcePp7700ksNyYn6uvPOO0OcX1M+9rGPhTi/psStNvLtE/IuuOCCEG+33XbJ3JFHHrnO18yyN57T0P3iR9yvueaaZO4Pf/hDiPv0SbeWNttssxBXa+XTXeKWY1mW1uq5556bzH3nO9+pez40zplnnhnizrTO+NznPpeMaz0PbzR34gIAAAAAFJhNXAAAAACAArOJCwAAAABQYL2uJ27cey7Lsuwb3/hGMn7llVdCfP755zckJ7rX6aef3uFjTz311BAvWbKkHunQg22xxRYV5xYuXNjATOipbrvttmS87bbb1vQ6jz76aIgnT57cpZzovMcffzzExx57bDK3yy67hHjMmDE1vf51111Xdf43v/lNiI877riKxy1fvrym96dYNt100xDH/Srz5s2bl4ynTp1at5zoOQ455JCq87fcckuIH3zwwXqnQ4PF/XHXNa5V/PmT77sa98Q94IADkrlhw4aF+OWXX+6WXEitWbMmxPnPiW222abiz73vfe8Lcd++fZO58847L8TVvr+mK+LvINh9993r8h40x2c+85lkHPc8zvdmzps5c2aIb7jhhu5NrEHciQsAAAAAUGA2cQEAAAAACqxXtFMYPnx4iH/6058mc+3t7ck4fnR1ypQp9U2MposfwVm1alXNr7N48eKKrxM/PrL++utXfI0NNtggGXe0LUT8iEuWZdlZZ50V4mXLlnXoNajN4YcfXnHuL3/5SwMzoVHiR7Pa2ir/f9Bqj5teddVVyXiTTTapeGz+PdauXftmKa7TEUccUdPPUX8PP/zwOuPu9O9//7tDx+2www7JeMaMGfVIhzrbe++9Q1xtnbrpppsakQ49TP7zbenSpcn4hz/8YSPToQe69tprk3HcTuEjH/lIMhe3xtMKsVjuuuuuinNxK6l8O4XVq1eH+Fe/+lUy94tf/CIZf+lLXwpxtfZBtL4999wzxPnPmSFDhlT8uXzLzM997nMhfu2117opu8ZyJy4AAAAAQIHZxAUAAAAAKDCbuAAAAAAABdYje+Lm+9xOnDgxxFtttVUyN3v27GT8jW98o36JUTiPPPJIt7zOn/70pxDPnz8/mdtoo41CnO/jVA/PPfdciC+88MK6v19vs88++4R44403bmImNMMVV1wR4osuuqjicbfccksyrtbLtjN9bjt67JVXXtnh16Tni3s5x3GeHrg9Q/xdEHkvvvhiiH/yk580Ih16gLiHYHxem2VZ9sILLyTjBx98sCE50XPlz3Xi860PfvCDydy3vvWtEP/xj39M5p588sk6ZEd3uOOOO0Kcv17t0+f1LaoTTzwxmRszZkwy3n///Tv0fvPmzetkhhRN/P0e6623XsXj8n3a457aWZZl//jHP7o3sSZwJy4AAAAAQIHZxAUAAAAAKLAe2U5h9OjRyXj33XeveOzpp5+ejPPtFWg9t912WzLOP3ZTD8ccc0xNP7d69eoQV3tM+uabb07GU6dOrXjsvffeW1MudMzRRx8d4nzrloceeijEkyZNalhONM4NN9wQ4jPOOCOZGzFiRN3ff8GCBSF+7LHHkrmTTjopxPm2LvRu5XJ5nTE900EHHVRxbu7cuSFevHhxI9KhB4jbKeTXkFtvvbXiz+UfeR06dGiI41qEah5++OEQf/Ob30zmLr744hB/97vfTeaOP/74EC9fvrxO2VGL+Bz22muvTeaOPfbYij93wAEHVJxbs2ZNMo7XprPPPruzKdJk+c+PM888s0M/9/vf/z4Z33333d2VUmG4ExcAAAAAoMBs4gIAAAAAFJhNXAAAAACAAusxPXG32GKLEN9xxx0Vj8v3MLzlllvqlhPN8aEPfSgZx/1T+vbt2+HXecc73hHij3zkIx3+uV/+8pfJ+Kmnnqp47PXXXx/ixx9/vMPvQeMMGjQoGR966KEVj73uuutCnO/LRM8wZ86cEI8fPz6ZO+qoo0J82mmn1eX9L7zwwhBfdtlldXkPep4BAwZUnNMnsPXlz23y3w0RW7FiRYhXrVpVt5zoPfLnO8cdd1yIv/zlLydzM2fODPEnP/nJ+iZGj/Tb3/42GX/2s58Ncf4a8Pzzzw/xI488Ut/E6JT43ONLX/pSMjdkyJAQjx07NpkbOXJkMo6vsydMmJDMnXfeeV3MkkaL/9s/+uijyVy1fZz47ztfTz2RO3EBAAAAAArMJi4AAAAAQIH1mHYKJ510Uog333zzisfdc889ybhcLtctJ4rhoosu6vJrfOxjH+uGTGhF+cdNFy5cGOKbb745mfvJT37SkJwohkmTJlUc59v6xJ9RRxxxRDIX19FVV12VzJVKpWScf7QIOuJTn/pUiBctWpTMXXDBBY1Oh262du3aZDx16tQQ77DDDsncrFmzGpITvcdnPvOZZPzpT386xP/93/+dzFlv6KoFCxYk4wMPPDDE+RZ2Z511VojjNh8Uy/PPP5+M4/Pk448/Ppnba6+9kvG3v/3tEL/wwgt1yI5Geu973xviTTfdNJmrtm8Xt+6J20b1VO7EBQAAAAAoMJu4AAAAAAAFZhMXAAAAAKDAWrYn7j777JOMv/CFLzQpE6Any/fE3XvvvZuUCa1k4sSJVcfQSP/7v/8b4ksuuSSZ+/vf/97odOhma9asScbnnHNOiPM95KZNm9aQnOhZTj311BCff/75yVy+P/wVV1wR4vh7BLIsy1auXFmH7OjN5s6dG+I777wzmTvyyCNDvP322ydzvmOgNUyYMKHqmJ4l7pterQfuxRdfnIx727msO3EBAAAAAArMJi4AAAAAQIG1bDuFfffdNxkPGTKk4rGzZ88O8ZIlS+qWEwBA0RxxxBHNToEGevbZZ0N8wgknNDETeorJkyeH+L3vfW8TM4HKxo0bl4ynT58e4jFjxiRz2ilA8QwbNizEpVIpmXvhhRdC/OMf/7hhORWRO3EBAAAAAArMJi4AAAAAQIHZxAUAAAAAKLCW7YlbTdz/Jsuy7H3ve1+IX3755UanAwAAANTJK6+8koy32mqrJmUC1OKSSy5ZZ5xlWXbBBReEeP78+Q3LqYjciQsAAAAAUGA2cQEAAAAACqxULpc7fnCp1PGDqbdp5XJ5bLOT6Ah1UxzlcrnU7Bw6Qs0UirWGWqgbaqFuqIW6oRbqhlqoGzrNNTg1qLjWuBMXAAAAAKDAbOICAAAAABSYTVwAAAAAgALr08njX8yybE49EqHTtmh2Ap2gbopBzVALdUMt1A21UDfUQt1QC3VDLdQNnaVmqEXFuunUF5sBAAAAANBY2ikAAAAAABSYTVwAAAAAgAKziQsAAAAAUGA2cQEAAAAACswmLgAAAABAgdnEBQAAAAAoMJu4AAAAAAAFZhMXAAAAAKDAbOICAAAAABSYTVwAAAAAgAKziQsAAAAAUGA2cQEAAAAACswmLgAAAABAgdnEBQAAAAAoMJu4AAAAAAAFZhMXAAAAAKDAbOICAAAAABRYn84cPGDAgPKQIUPCeNWqVRWPffXVV0Pc3t6ezK1evbozb9trDRo0KMRtbel++5IlS14sl8sjGp1TLfr3718ePHhwGFermyVLloQ4/29eu3Zt9yfXA/Xv3z/E8e9w5cqV2erVq0vNyKmz8mtNvGaUy+Xk2Lhm8mtNtVrjdfHfZ6mUlkirrTXxurly5cqKxy5btizE+X9zvsZYt379+oU4/zt87bXXWqpuKp3bdGa9WbNmTZ0y7FkGDBgQ4vzn/LJly1qmbpwTN1a8tufXm6VLl7ZU3VQ6J7bedL+est64lmqsStdSWZZly5cvb9m6qXZevHTp0hCrm9rE58Xx73DVqlUtcw2uZhorXmvy5zYrVqyouNZ0ahN3yJAh2eGHHx7GL7zwQojzJx533313iDfYYINk7rnnnquYbG+7eI7//fnfxfbbbx/i+CQky7Js8uTJc+qbWfcZPHhwdtBBB4XxvHnzKh57//33hzg+Yc+y9CKIyrbccssQx3Xz5JNPNiGb2gwZMiQ74ogjwnjBggUhzn8o3HPPPSEeOnRoMvfMM8+EuLevNfGHa/53scMOO4Q4/jDJsiybNGlSy6w1gwYNyt73vveF8Zw5lVOfNm1aiPPr6/Lly7s/uR5o1KhRIc7/Dp944omWqZshQ4Ykn1HxOUp+nZg8eXLyc7FFixbVKcPWll9vRo8eHeJ83UybNq2l6uawww4L41rPiZ9//vkQ9/bPqWrnxNttt12I859T9913X8vUzeDBg7NDDjkkjJ999tkQV1tv1ltvvWRu4cKFdcqwtVlNbYwAABNZSURBVOXrZsyYMSHO100rrTf5a6m4bvLnxfG1VLwZk2VZ9sorr9Qpw56l0rVUlmXZ9OnTW6puDjzwwDB++umnKx77wAMPhDj/b45vfKCyTTfdNMTxhu5TTz3VhGxqM3jw4Oz9739/GMfX0vnPqClTpoQ4v28T/88kKttss81CnP+7mzFjRsW1RjsFAAAAAIACs4kLAAAAAFBgnWqnkBc/cho/1pFlaa+m3n4LfvwYc/6Rl6233jrE+d9h/CjHo48+Wp/kmqBa3cS/n9dee61hObWakSNHhvill15K5uJHxx555JEQt3LfvXgNmT9/fjIX/7vi3jx5veEx1bhnXr5fXlwX8aMxWZZlm2++eYgfe+yxOmXXeHHdxI/IZ1n6379av6feLn70e/Hixcnc2972thDHa02ri+um2mfUihUrGpZTEcVran49jVttxO1wsiw97/nXv/5Vp+waI/4ddLRunBNXPifeYostQpxfs+Nz4pkzZ9YnuSbo6Dlxb2/zU2292WSTTUJcbb2ZMWNGnbKrv1KplPwO4vPd/Hlx/PtxLVVZLddSrajS51S1unFeXNmwYcNCnG+j1VOuwa013WvDDTcMcb4VUq3XUu7EBQAAAAAoMJu4AAAAAAAFVurMI8Xt7e3l+Jvn4kd78o/u0nXxo9H5R87K5fK0crk8ttE51aKtra3cp8/rnTtWrVrVxGx6vmqPnJXL5VL++CJqb28vx9/8Hj/KYa3pfvHfZ36tWbt2bcusNaVSqVytpQQN1TJ109bWVo6/RTh+jLAntl1ptmqfUVkL1U17e3t54MCBYRyfE+fXUbquJ50TW28ap6esN66lGqun1E2pVErqptUe6+9JWuUaXM0USsW1xp24AAAAAAAFZhMXAAAAAKDAbOICAAAAABRYnzc/5HVtbW3Z4MGDw3jZsmXdnhCvi3uCLl68uImZdE2pVMr69+8fxvo41Vffvn1DHPdaayXt7e3JWhP3xKX7rbfeeiFeuHBhEzPpmlKplPT31RO3vnpKz6y2trZswIABYdyq62ariH/XcR/ZVtPW1pZV+p4Iul98TvDKK680MZOuaWtry+Jeytab+uop641rqcaK+1a/9tprTcyka9ra2pJ/Syufq7WC+Bq8Vf9G29rakrVGzdRXpR75b8aduAAAAAAABWYTFwAAAACgwDrVTmH16tXZ888/X69cyGnlFgqxtWvXZkuWLGl2Gr1GT3g0b9WqVdn8+fObnUav0cotFGLlcrmlH3trNT3lEas1a9b0mM/bVtDKjzTHVq9enS1YsKDZafQardxCIbZmzZps0aJFzU6j1+gp641rqcbqKeeSa9eu1f6ygVq1hUJs7dq12hg2UK37Nu7EBQAAAAAoMJu4AAAAAAAFZhMXAAAAAKDAOtUTF6BRSqVSiMvlchMz6fn8rgEAAKDY3IkLAAAAAFBgNnEBAAAAAApMOwWgkDzW3zh+1wAAAFBs7sQFAAAAACgwm7gAAAAAAAVmExcAAAAAoMB6ZE/cfH/HUqnUobksy7JvfvObIT7//PPrkB1F1ZW6mTBhQoiPP/74OmRHEXWlZr72ta+F+Hvf+14dsqOoulI3t956a4gPO+ywOmRHUXWlbn7xi1+E+MQTT6xDdhRVV+rmggsuCPE3vvGNOmRHUTknphZdqZuzzjorxN///vfrkB1F1ZW6iWslriF6tq7UzOWXXx7ik08+uQ7Z1Z87cQEAAAAACswmLgAAAABAgZXytxtXPbhU6vjB1Nu0crk8ttlJdIS6KY5yuVx686OaT80UirWGWqgbaqFuqIW6oRbqhlqoGzrNNTg1qLjWuBMXAAAAAKDAbOICAAAAABSYTVwAAAAAgALr0+wEapXv5Vsqlbo8l2VZdu2114b42GOP7XKeFEu96uaOO+4I8Qc+8IEu50lx1KtmzjzzzBBfdNFFXc6TYqlX3Tz44IMh3m233bqcJ8VSr7q5//77Q/yud72ry3lSLPWqm1/84hchPvHEE7ucJ8VSr7r5/ve/H+Kzzjqry3lSLPWqmzPOOCPEF198cZfzpFjqVTcTJ04M8cEHH9zlPCmOetXMZZddFuJTTjmly3k2gztxAQAAAAAKzCYuAAAAAECBlfK3G1c9uFTq+MHU27RyuTy22Ul0hLopjnK5XHrzo5pPzRSKtYZaqBtqoW6ohbqhFuqGWqgbOs01ODWouNa4ExcAAAAAoMBs4gIAAAAAFJhNXAAAAACAAuvT7ARqle/lWyqVujyXn8/P0frUDZ2lZqiFuqEW6oZaqBtqoW6ohbqhFuqGzlIzlbkTFwAAAACgwGziAgAAAAAUWMu2U6h263Otcx2Zp7WpGzpLzVALdUMt1A21UDfUQt1QC3VDLdQNnaVmKnMnLgAAAABAgdnEBQAAAAAoMJu4AAAAAAAF1rI9ccvlcjKOe1vUOkfPp27oLDVDLdQNtVA31ELdUAt1Qy3UDbVQN3SWmqnMnbgAAAAAAAVmExcAAAAAoMBatp1Ctdui83N77bVXxWPzt1vHrr322mR87LHHduj9Ka7O1M3BBx9c8dhqdXP//fcn43e9610den+KqTM18+Uvf7nisdVq5vLLL0/GJ598cofen+JqxFrzr3/9KxnvuOOOHXp/iqszdbPbbrtVPLZa3UyePDkZ77PPPh16f4qrM3Xz7ne/u+Kx1ermtttuS8aHHnpoh96f4upM3Zx99tkVj61WN/fee28y3nfffTv0/hRXZ+rmyCOPrHisa/DepTN1s9NOO1U8tlrdPPTQQ8l411137dD7U0ydqZmjjjqq4rHVambSpEnJeL/99uvQ+zebO3EBAAAAAArMJi4AAAAAQIHZxAUAAAAAKLBStR4Rbzi4VOr4wXVWre/oBhtskMwtWrSoITk12LRyuTy22Ul0RJHqZv78+cl41KhRIe7fv38y99prrzUkp0Yql8vFbe4SKVLN3Hzzzck47u8V10+WvbG+eghrTQ1efvnlZDxs2LAQt7e3J3Nr1qxpSE4Npm5q8OyzzybjTTbZJMQDBw5M5pYvX96QnBpM3dTgiSeeSMbbbrttiN/ylrckc6+88kpDcmowdVODan3VhwwZkswtWbKkITk1mLqpwezZs5Px6NGjQ+xzqliKVDcLFy5MxkOHDg3xoEGDkrlly5Y1JKdGcg3eedVqpm/fvsncqlWrGpJTg1Vca9yJCwAAAABQYDZxAQAAAAAKzCYuAAAAAECBtWxP3LzTTjstxD/+8Y+75TWnTp2ajMeOfb0lRanU9LYm+vF0gwsuuCDE5557bre85sMPP5yMd9lllxA3u2704+m6q6++OsTjx4/vlte87rrrkvG4ceNC3Oyayaw13aIea021Ht/qpuOKXDef//znQ3z55Zd3y2vOmjUrGY8ZMybE6qbjilw3X/va10L83e9+t1te85///Gcyfuc73xliddNxRa6ba665JsTHHntst7zm9ddfn4w//OEPh1jddFyR62bChAkh/vjHP94tr2m96R5FrptLL700xKeeemq3vGa1/vDNrhvX4F3361//OsSf/OQnu+U1p0yZkoz32muvEDe7ZjI9cQEAAAAAWpNNXAAAAACAAusx7RR6IY9y0Gke5aAG1hpqoW6ohbqhFuqGWqgbaqFu6DTX4NRAOwUAAAAAgFZkExcAAAAAoMBs4gIAAAAAFFifZifQXTrT27ejSqW0dUn8Hvk5WpO6obPUDLVQN9RC3VALdUMt1A21UDfUQt3QWWrmde7EBQAAAAAoMJu4AAAAAAAF1mPaKTTiduci31JNbdQNnaVmqIW6oRbqhlqoG2qhbqiFuqEW6obOUjOvcycuAAAAAECB2cQFAAAAACgwm7gAAAAAAAXWY3riLl26NMTXX399Mnf88cdX/Ll834tyuVxxbs2aNSFub2+vKU+KZfXq1SG+/fbbk7nDDz+84s91pm6qzdF6Xn311RD/4x//SOYOOuigij/Xmbp47bXXQty/f/+a8qRY1q5dG+JJkyYlc+95z3sq/py1pndbtWpViK+77rpkbvz48RV/Tt30bsuXLw/xX/7yl2TumGOOqfhzzol7t5UrV4b44YcfTub22GOPij/XmbqJPwvb2txL1BPE11IPPvhgMtdddeNzqueJ14KZM2cmczvssEPFn1M3vVe81tx7773J3P7771/x53pizfj0BAAAAAAoMJu4AAAAAAAF1mPaKQwePLji3Cc+8YkOv06126Y9Ltbz9OnTPX8C1eqmyLfi03nrrbdet7xOtbrQQqHn6a7HRq01vUvfvn0rzn30ox/t8Ouom95l4MCB3fI6zol7l379+nXL61SrGy0Ueh7XUtTCeTGdZa15nU9SAAAAAIACs4kLAAAAAFBgNnEBAAAAAAqsS40l4r4Uq1ev7nIyjbB8+fJknO8bVi6XQ5zviXHUUUeF+KabbqpDdr1D/HuNf99FtmbNmmSc7wVXrW723nvvEN933311yK7ni/tCrlq1qomZdNyyZcuS8aBBg5JxtZrZf//9Q3z33Xd3e24U19q1a5NxvmdYtboZO3ZsiKdOnVqH7HqH+Hee/+9RVPlzsHzfsGp18/73vz/Ef/3rX+uQXe/QiufEK1asSMYDBgxIxtXq5pBDDgnx7bffXofseofett7svPPOIZ4+fXodsusdWvFaqit1s9dee4V4ypQpdciOourKefFuu+0W4gcffLAO2fV8rbjWdGXfZvfddw/xtGnT6pBd93AnLgAAAABAgdnEBQAAAAAosFJnbosulUqtcQ917zCtXC6PffPDmk/dFEe5XC69+VHNp2YKxVpDLdQNtVA31ELdUAt1Qy3UDZ3mGpwaVFxr3IkLAAAAAFBgNnEBAAAAAArMJi4AAAAAQIH16czBpVIp69evXxi/7W1vC/GMGTOSY9vaXt8fXrt2ba350UPE9bDZZpuFeM6cOc1Ih4IrlUpZ//79w3jbbbcN8fTp05NjrTXESqXXW05ttNFGIX7uueeakQ4tor29PcRbbbVViGfNmtWMdGgBpVIp69u3bxjH58QzZ858w7H/0ZnvoqBnst5QC9dS1CL+/Bk1alSIn3322WakQwuI15q3vvWtIX766aebkQ7r4E5cAAAAAIACs4kLAAAAAFBgpc481lUqlcp9+rzegSH+2TVr1nRrYrypaeVyeWyzk+iIUqlUjh/liHmssLHK5fK6/0MUTFtbW8W1ZvXq1c1IqTdrqbWm2TkQtFTdxI+OxeuNz6iGa6m6cU5cGC1VN9abwmipunEtVRgtVTfNzoH/r1WuwfNrjfWlqSquNe7EBQAAAAAoMJu4AAAAAAAFZhMXAAAAAKDA+rz5Ia8bMGBANmbMmDDebLPNQvy3v/0tOXb48OEhfvbZZ9/wOv+xYsWKzqTQ48Q9RwYOHJjMrb/++iEePHhwMjdr1qz6JtaN+vXrl40aNSqMt9xyyxDfe++9ybHrrbdeiBcvXpzMtbe3h1i/udfFPfmyLMsGDRq0zvjFF19sWE5dNWDAgGybbbYJ43itufPOO5NjR4wYEeKnn346mYv//cuWLevuNFtKvNbk15MNNtggxEOGDEnmHn/88fom1o369OmTbbjhhmG8xRZbhPiBBx5Ijo3X23xt6AW1bnEfxyzLsv79+4c4/lzPsixbuHBhQ3LqDv3798823XTTMN58881DPGnSpOTY+HP55ZdfTubitVjv7tf17ds3GcdrTH4tmjdvXkNy6g4DBgzIRo8eHcZx3dx1113JsfE58fz589/wOv/hnPj1tTe/plQ7J549e3Z9E+tG/fv3T85p4s+pu+++Ozm22noT/12tWrWqm7NsXf369UvG1dab/DljkfXr1y/bZJNNwjiuG9dSXZe/loprJb6WyLI3ruFF1rdv34rnxf/85z+TY+N/59KlS5O5+Pxv7dq13Z1my4r/nrIs/dyKrzMWLVrUsJy6ql+/ftnGG28cxvG5zX333ZccG6+vr7zySjJnrVm3fM1U2rfJsix7/vnnK76OO3EBAAAAAArMJi4AAAAAQIF1qp1Cnz59kkfC4lt840eg8nN5vf1xsVj8qG7+kd54HD+22mrydfPMM8+EOF83+VvxY27FX7f8Y7vx73DJkiUhbqXHX/r06ZMNGzYsjJ977rkQ5x/prvZYU29voRCL15q4LvLj/COsrSS/1uRb+cSq1YYWCuuWX0OWL18e4lb+XG9vb6/4uHv+M6pamwgtFNYt/6h3/Dus9plfdPn1Jq6b/OfUCy+8UPF1Wvlvp7vFa2+8vuTH+UfmW0lnzomrrTdaKKzbypUrk3HchiLfWqCVuJaqr/znd1wrr776aqPT6Tb585v4vDhfN/kWCrFWuoZspPzfU/w7jK8zWum6or29PbkGr3ZObK3pvPzvJV5fqv0N5rkTFwAAAACgwGziAgAAAAAUmE1cAAAAAIACK3WmR0epVFqQZdmc+qVDJ2xRLpdHNDuJjlA3haFmqIW6oRbqhlqoG2qhbqiFuqEW6obOUjPUomLddGoTFwAAAACAxtJOAQAAAACgwGziAgAAAAAUmE1cAAAAAIACs4kLAAAAAFBgNnEBAAAAAArMJi4AAAAAQIHZxAUAAAAAKDCbuAAAAAAABWYTFwAAAACgwP4fbebsavocZhEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1800x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# get sample outputs\n",
    "output = decoder(encoder(images))\n",
    "# prep images for display\n",
    "images = images.numpy() # output is resized into a batch of iages\n",
    "output = output.view(batch_size, 1, 28, 28)\n",
    "# use detach when it's an output that requires_grad\n",
    "output = output.detach().numpy()\n",
    "\n",
    "# plot the first ten input images and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))\n",
    "\n",
    "# input images on top row, reconstructions on bottom\n",
    "for images, row in zip([images, output], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(np.squeeze(img), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        if torch.randn(1) > 0:\n",
    "            ## Training the discriminator\n",
    "            #----------------------------\n",
    "            # forward path\n",
    "            real_output = discriminator(z_real)\n",
    "            fake_output = discriminator(z_fake)\n",
    "            d_loss = -torch.mean(torch.log(real_output + 1e-15) + torch.log(1 - fake_output + 1e-15))\n",
    "\n",
    "            # back propagation\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "        \n",
    "        ## optimize the generator\n",
    "        #------------------------\n",
    "        encoder.train()\n",
    "        z_fake = encoder(img)\n",
    "        fake_output = discriminator(z_fake)\n",
    "        g_loss = -torch.mean(torch.log(fake_output + 1e-15))\n",
    "        #g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), PATH)\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
